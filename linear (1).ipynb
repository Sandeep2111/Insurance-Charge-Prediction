{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Importing Necessary libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n%matplotlib inline\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/insurance/insurance.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's just print the First 5 rows to get an overview of how the Data Looks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### ***isnull*** function is used to check if there is any null values in Dataset and counting null values if there is any.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the type of data in the Dataset field,we can see that the Dataset contains both numerical and categorical values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since Dataset is of Numerical and Categorical Data, Let's convert categorical values into Numerical for easy computing and Extract Information on the Dataset. Before that Let's find out what are the Unique values in categorical Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical=['sex','smoker','region']\n\nfor col in categorical:\n    print(col,'Column has {} as unique values'.format(data[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nLe=LabelEncoder()\n\nfor col in categorical:\n    Le.fit(data[col].drop_duplicates())\n    data[col]=Le.transform(data[col])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Dataset is now converted into Numerical Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's Find the Descriptive statistics of the Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(figsize=(15,12))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"by histogram we can get to know the Distribution of the data for each column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Correlation function corr() computes pairwaise correlation of each column,The values ranges from -1 to +1 where -1 indicates it is higly negativel correlated which has zero effect on the outcome whereas +1 indicates the data is higly possitively correlated which means, the outcome is higly dependent on that Variable. \n\n\nCorrelation function plotted with heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.heatmap(data.corr(),annot=True,cmap='Oranges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By the heatmpa figure we can see that charges and smoker are higly correlated which means that the people who smokes end up in hospital paying high charges for treatment.\n\nwhereas the age and bmi body mass index is slightly correlated by which we can believe that, the charges varies depending on the age of the people","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot distribution of charges for smokers\nf=plt.figure(figsize=(15,7))\nax=f.add_subplot(121)\nsns.distplot(data[data.smoker==1]['charges'],color='c',ax=ax)\nax.set_title('Distribution of charges for smokers')\n\n#plot distribution of charges for non smokers\nax=f.add_subplot(122)\nsns.distplot(data[data.smoker==0]['charges'],color='b')\nax.set_title('Distribution of charges for non smokers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The charges for smokers is quite high as compared with non smokers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='smoker',hue='sex',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# sex:          \nmale=1                       \n\nfemale=0                      \n\n# smoker:\n smoker=1\n \n non-smoker=0\n \ncount of male smokers is quite high as compared with female smokers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='sex',y='charges',hue='smoker',kind='violin',data=data,palette='magma')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.boxplot(x='charges',y='smoker',data=data[data.sex==1],orient='h')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.boxplot(x='charges',y='smoker',data=data[data.sex==0],orient='h',palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Median Charges for Male is Higher as compared with Female Smokers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.title('Dist of age')\nsns.distplot(data['age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count of smokers who are exactly 18 years old \nsns.countplot(x='smoker',hue='sex',data=data[data['age']==18])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='age',y='charges',hue='smoker',data=data,size=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count of People who has Children and Smokes\nsns.countplot(x='smoker',hue='sex',data=data[data.children>0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The count of people who has Children and Smoke are less as compared with people who smokes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import r2_score,mean_squared_error,roc_auc_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train the Model with Linear Regression and check the accuracy\n\nX=data.drop(['charges'],axis=1)\ny=data.charges\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)\n\n# std=StandardScaler()\n# X_train=std.fit_transform(X_train)\n# X_test=std.transform(X_test)\n\n\nlr=LinearRegression()\nlr.fit(X_train,y_train)\ntest=lr.predict(X_test)\nr2_score(y_test,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge,Lasso\n\nfor alpha in [0.0001,0.001,0.01,0.1,1,10,100]:\n    Rid=Ridge(alpha=alpha).fit(X_train,y_train)\n    rid_test=Rid.predict(X_test)\n    print('Accuracy scorer for alpha {} is '.format(alpha),r2_score(y_test,rid_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model with Lasso with different alpha values\nfor alpha in [0.0001,0.001,0.01,0.1,1,10,100]:\n    Las=Lasso(alpha=alpha).fit(X_train,y_train)\n    las_test=Las.predict(X_test)\n    print('Accuracy scorer for alpha {} is '.format(alpha),r2_score(y_test,las_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best accuracy is 79 when compared with Liner models, Let's check with Different Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can apply increase the number of features by applying polynomial features with the required degree, Which generates a new feature matrix of polynomial combination.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n\npoly=PolynomialFeatures(2)\n\npoly_train=poly.fit_transform(X_train)\npoly_test=poly.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree=DecisionTreeRegressor()\ntree.fit(poly_train,y_train)\ntrain_predict=tree.predict(poly_train)\nprint('train_score',r2_score(y_train,train_predict))\ntree_test_result=tree.predict(poly_test)\nprint('test_score',r2_score(y_test,tree_test_result))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is Overfitting, We can apply gridsearchCV method to find the best parameters for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparameters=[{'min_samples_split':[2,5,15,25,50,60,70,80,100],'criterion':['mse','friedman_mse','mae']}]\n\ngrid=GridSearchCV(estimator=tree,param_grid=parameters,cv=10,n_jobs=-1)\n\ngrid=grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree=DecisionTreeRegressor(min_samples_split=30,criterion='mae')\ntree.fit(poly_train,y_train)\ntree_test_result=tree.predict(poly_test)\nprint('test_score',r2_score(y_test,tree_test_result)*100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate\n\nscore=cross_validate(tree,X,y,cv=10,scoring='r2',return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score['test_score'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\nspl=[]\nsco=[]\nfor split in [2,5,10,20,30,40,50,100,150,200,300]:\n    tree=DecisionTreeRegressor(min_samples_split=split,criterion='mae')\n    tree.fit(poly_train,y_train)\n    tree_test_result=tree.predict(poly_test)\n    test_score=r2_score(y_test,tree_test_result)\n    spl.append(split)\n    sco.append(test_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.plot(spl,sco)\nplt.title('Test score compared with min_samples_split')\nplt.xlabel('min_samples_split')\nplt.ylabel('Test Score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the figure we can see that as the min_samples_split is increased the test score is increased after 40 min_samples_split the tests score result starts decreasing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}